{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d927120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/users/kcochran/projects/domain_adaptation_nosexchr/\"\n",
    "\n",
    "# shorthand for each TF name\n",
    "tfs = [\"CTCF\", \"CEBPA\", \"Hnf4a\", \"RXRA\"]\n",
    "\n",
    "# shorthand names for all model training types to generate predictions for\n",
    "all_trainspecies = [\"mm10\", \"DA\", \"hg38\", \"NS\"]\n",
    "\n",
    "# these are specifically the \"species\" with test datasets to evaluate on\n",
    "all_testspecies = [\"mm10\", \"hg38\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2a978",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from seqdataloader.batchproducers.coordbased.core import Coordinates\n",
    "from seqdataloader.batchproducers.coordbased.coordstovals.fasta import PyfaidxCoordsToVals\n",
    "\n",
    "GENOMES = {\"mm10\" : \"/users/kcochran/genomes/mm10_no_alt_analysis_set_ENCODE.fasta\",\n",
    "            \"hg38\" : \"/users/kcochran/genomes/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"}\n",
    "\n",
    "\n",
    "def get_test_bed_file(species):\n",
    "    # This function returns the path to a BED-format file\n",
    "    # containing the chromosome names, starts, and ends for\n",
    "    # all examples to test the model with.\n",
    "    # Note binding labels will not be loaded in.\n",
    "    # This file should contain the same examples for any TF.\n",
    "    return(ROOT + \"data/\" + species + \"/\" + tfs[0] + \"/chr2.bed\")\n",
    "\n",
    "\n",
    "class ValGenerator(Sequence):\n",
    "    # This generator retrieves all coordinates for windows in the test set\n",
    "    # and converts the sequences in those windows to one-hot encodings.\n",
    "    # Which species to retrieve test windows for is specified with\n",
    "    # the \"val_species\" argument. \n",
    "    \n",
    "    def __init__(self, batchsize, val_species = \"hg38\"):\n",
    "        self.valfile = get_test_bed_file(val_species)\n",
    "        self.get_steps(batchsize)\n",
    "        self.converter = PyfaidxCoordsToVals(GENOMES[val_species])\n",
    "        self.batchsize = batchsize\n",
    "        self.get_coords()\n",
    "        \n",
    "        \n",
    "    def get_steps(self, batchsize):\n",
    "        # calculates the number of steps needed to get through\n",
    "        # all batches of examples in the test dataset\n",
    "        # (Keras predict_generator code needs to know this)\n",
    "        with open(self.valfile) as f:\n",
    "            lines_in_file = sum(1 for line in f)\n",
    "        \n",
    "        self.steps = lines_in_file // batchsize\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def get_coords(self):\n",
    "        # load all coordinates for the test data into memory\n",
    "        with open(self.valfile) as f:\n",
    "            coords_tmp = [line.rstrip().split()[:3] for line in f]\n",
    "            \n",
    "        assert [len(line_split) == 3 for line_split in coords_tmp]\n",
    "        self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "        # convert a batch's worth of coordinates into one-hot sequences\n",
    "        batch = self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        return self.converter(batch)\n",
    "    \n",
    "\n",
    "def get_preds_batched_fast(model, batch_size, test_species = \"hg38\"):\n",
    "    # Make predictions for all test data using a specified model.\n",
    "    # Batch_size can be as big as your compute can handle.\n",
    "    # Use test_species = \"mm10\" to test on mouse data instead of human data.\n",
    "    \n",
    "    print(\"Generating predictions...\")\n",
    "    return np.squeeze(model.predict_generator(ValGenerator(batch_size, test_species),\n",
    "                                               use_multiprocessing = True, workers = 8, verbose = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090762af",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to load DA models\n",
    "\n",
    "from flipGradientTF import GradientReversal\n",
    "import tensorflow\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # this should be the same implementation as what was used when the DA model trained\n",
    "    y_pred = tensorflow.boolean_mask(y_pred, tensorflow.not_equal(y_true, -1))\n",
    "    y_true = tensorflow.boolean_mask(y_true, tensorflow.not_equal(y_true, -1))\n",
    "    return keras.losses.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70477a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_file(tf, train_species, run = 1, model_type = \"best\"):\n",
    "    # This function returns the filepath where the model for a given\n",
    "    # TF, training species, and run is saved.\n",
    "    # By default, the file for the best model across all training epochs\n",
    "    # is returned, you can change model_type to select the last model instead.\n",
    "    # This function specifically looks for the most recent model file,\n",
    "    # if there are multiple for the same run-TF-species combo.\n",
    "    try:\n",
    "        run_int = int(run)\n",
    "    except:\n",
    "        print(\"Error: You need to pass in a run number that can be cast to int.\")\n",
    "    \n",
    "    model_file_prefix = ROOT + \"/\".join([\"models\", tf, train_species + \"_trained\", \"basic_model/\"])\n",
    "        \n",
    "    if train_species == \"DA\":\n",
    "        # assuming all DA models are mouse-trained\n",
    "        model_file_prefix = model_file_prefix.replace(\"DA\", \"mm10\")  \n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"DA\")\n",
    "    if train_species == \"NS\":\n",
    "        # assuming the no-SINEs models are trained on human data\n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"basic_model_nosines\")\n",
    "        model_file_prefix = model_file_prefix.replace(\"NS\", \"hg38\")        \n",
    "    \n",
    "    # these models were saved as part of training\n",
    "    # see ../2_train_and_test_models/callbacks.py for model saving details \n",
    "    if model_type == \"best\":\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_best.model\"\n",
    "    else:\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_15E_end.model\"\n",
    "    \n",
    "    # get all files that match the prefix and suffix\n",
    "    files = [f for f in os.listdir(model_file_prefix) if f.endswith(model_file_suffix)]\n",
    "    \n",
    "    # sort files and return the one that is most recent\n",
    "    latest_file = max([model_file_prefix + f for f in files], key=os.path.getctime)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "def load_keras_model(model_file, DA = False):\n",
    "    print(\"Loading \" + model_file + \".\")\n",
    "    if DA:\n",
    "        # need to tell Keras how the GRL and the custom loss was implemented\n",
    "        # (these need to match the definitions from when the model was saved)\n",
    "        return keras.models.load_model(model_file,\n",
    "                custom_objects = {\"GradientReversal\":GradientReversal,\n",
    "                                  \"custom_loss\":custom_loss})\n",
    "    return keras.models.load_model(model_file)\n",
    "\n",
    "\n",
    "def get_models_all_runs(tf, train_species, runs = 5):\n",
    "    # load in models for all runs, for a given TF and training species\n",
    "    # returns a list of Keras model objects\n",
    "    models = []\n",
    "    for run in range(runs):\n",
    "        model_file = get_model_file(tf, train_species, run + 1)\n",
    "        models.append(load_keras_model(model_file, DA = train_species == \"DA\"))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521eddc",
   "metadata": {},
   "source": [
    "# Generate + Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828df5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_file(tf, train_species, test_species):\n",
    "    preds_root = ROOT + \"model_out/\"\n",
    "    os.makedirs(preds_root, exist_ok=True)\n",
    "    return preds_root + tf + \"_\" + train_species + \"-trained_\" + test_species + \"-test.preds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a223052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### This cell takes a while (hours) to run.\n",
    "\n",
    "# loop over mouse and human, the two species to evaluate models in\n",
    "for test_species in all_testspecies:\n",
    "    # loop over mouse-trained, human-trained models\n",
    "    for train_species in all_trainspecies:  \n",
    "        for tf in tfs:\n",
    "            print(\"\\n===== \" + tf + \" \" + test_species + \" test, \" + train_species + \" trained =====\\n\")\n",
    "\n",
    "            # load the 5 independently trained models for the given tf and training species\n",
    "            models = get_models_all_runs(tf, train_species)\n",
    "            \n",
    "            # generate predictions for all 5 independent model runs on human data\n",
    "            all_model_preds = np.array([get_preds_batched_fast(model, 1024, test_species = test_species) for model in models])\n",
    "            \n",
    "            # if we got the output of DA model, throw out species preds and keep binding preds\n",
    "            if train_species == \"DA\" and len(all_model_preds.shape) > 2:\n",
    "                all_model_preds = all_model_preds[:, 0, :]\n",
    "            assert len(all_model_preds.shape) == 2, all_model_preds.shape\n",
    "            \n",
    "            # save predictions to file\n",
    "            preds_file = get_preds_file(tf, train_species, test_species)\n",
    "            np.save(preds_file, all_model_preds.T)\n",
    "\n",
    "            # clear variables and model to avoid unnecessary memory usage\n",
    "            del all_model_preds, tf, models\n",
    "            keras.backend.clear_session()\n",
    "        del train_species\n",
    "    del test_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad4a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:da2]",
   "language": "python",
   "name": "conda-env-da2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
