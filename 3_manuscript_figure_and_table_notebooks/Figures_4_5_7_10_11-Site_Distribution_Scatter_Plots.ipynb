{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "ROOT = \"/users/kcochran/projects/domain_adaptation/\"\n",
    "\n",
    "# shorthand for each TF name\n",
    "tfs = [\"CTCF\", \"CEBPA\", \"Hnf4a\", \"RXRA\"]\n",
    "# plot-acceptable TF names\n",
    "tfs_latex_names = [\"CTCF\", \"CEBPα\", \"HNF4α\", \"RXRα\"]\n",
    "\n",
    "# shorthand names for all model types to include in plots\n",
    "all_trainspecies = [\"mm10\", \"DA\", \"hg38\", \"NS\"]\n",
    "# plot-acceptable names for model types\n",
    "model_names_dict = {\"mm10\" : \"Mouse\",\n",
    "                    \"hg38\" : \"Human\",\n",
    "                    \"DA\" : \"Mouse+DA\",\n",
    "                    \"NS\" : \"Human-NS\"}\n",
    "\n",
    "# Constants to be used for plot appearance details\n",
    "DOT_SIZE = 5\n",
    "ALPHA = 0.03\n",
    "AXIS_SIZE = 11\n",
    "AX_OFFSET = 0.02\n",
    "TF_TWINAX_OFFSET = 0.35\n",
    "FIG_SIZE_UNIT = 5\n",
    "FIG_SIZE_2_by_4 = (FIG_SIZE_UNIT, FIG_SIZE_UNIT * 2)\n",
    "FIG_SIZE_1_by_2 = (FIG_SIZE_UNIT / 2, FIG_SIZE_UNIT)\n",
    "BOUND_SUBSAMPLE_RATE = 4\n",
    "\n",
    "import random\n",
    "random.seed(1234) \n",
    "\n",
    "# If you don't care about testing the model on all examples\n",
    "# and want to speed things up, you can set SKIP to not None;\n",
    "# every SKIP-th ***UNBOUND*** example will be used in model evaluation.\n",
    "# Be careful -- make sure that *everywhere* in the code,\n",
    "# the same SKIP value is being used!\n",
    "# Note that since bound sites are so sparse, SKIP only applies\n",
    "# to UNBOUND sites.\n",
    "SKIP = 200\n",
    "\n",
    "MODEL_TYPE = \"best\"  # used to use early stopping but not anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to load DA models\n",
    "\n",
    "from flipGradientTF import GradientReversal\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_pred = tensorflow.boolean_mask(y_pred, tensorflow.not_equal(y_true, -1))\n",
    "    y_true = tensorflow.boolean_mask(y_true, tensorflow.not_equal(y_true, -1))\n",
    "    return keras.losses.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from seqdataloader.batchproducers.coordbased.core import Coordinates\n",
    "from seqdataloader.batchproducers.coordbased.coordstovals.fasta import PyfaidxCoordsToVals\n",
    "\n",
    "ROOT = \"/users/kcochran/projects/domain_adaptation/\"\n",
    "\n",
    "GENOMES = {\"mm10\" : \"/users/kcochran/genomes/mm10_no_alt_analysis_set_ENCODE.fasta\",\n",
    "           \"hg38\" : \"/users/kcochran/genomes/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"}\n",
    "\n",
    "\n",
    "def get_test_bed_file(species, tf):\n",
    "    # This function returns the path to a BED-format file\n",
    "    # containing the chromosome names, starts, and ends for\n",
    "    # all examples to test the model with.\n",
    "    # Note this is specific to a TF (binding labels\n",
    "    # are loaded in from this file)!\n",
    "    return(ROOT + \"data/\" + species + \"/\" + tf + \"/chr2.bed\")\n",
    "\n",
    "\n",
    "class UnboundTestGenerator(Sequence):\n",
    "    # This generator retrieves all coordinates for ***UNBOUND*** windows\n",
    "    # in the test set, converting their sequence to one-hot encodings.\n",
    "    \n",
    "    # If you don't care about testing the model on all examples\n",
    "    # and want to speed things up, uyou can set SKIP to not None;\n",
    "    # every SKIP-th example will be used in model evaluation.\n",
    "    # Be careful -- be consistent with the SKIP value you choose!\n",
    "    \n",
    "    def __init__(self, batchsize, val_file, skip = None):\n",
    "        self.valfile = val_file\n",
    "        self.get_steps(skip, batchsize)\n",
    "        # the plots we're making are for the human test data only\n",
    "        assert \"hg38\" in val_file\n",
    "        self.converter = PyfaidxCoordsToVals(GENOMES[\"hg38\"])\n",
    "        # batchsize here is just how many examples to evaluate at once,\n",
    "        # not the training batchsize; go a high as your GPU can fit\n",
    "        self.batchsize = batchsize\n",
    "        self.get_unbound_coords(skip)\n",
    "        \n",
    "        \n",
    "    def get_steps(self, skip, batchsize):\n",
    "        # calculates the number of steps needed to get through\n",
    "        # all batches of UNBOUND examples\n",
    "        # (Keras predict_generator code needs to know this)\n",
    "        with open(self.valfile) as f:\n",
    "            # if condition tests that the example is unbound\n",
    "            lines_in_file = sum([1 for line in f if line.rstrip().split()[-1] == \"0\"])\n",
    "        if skip is None:\n",
    "            self.steps = lines_in_file // batchsize\n",
    "        else:\n",
    "            self.steps = (lines_in_file // skip) // batchsize\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "\n",
    "    def get_unbound_coords(self, skip):\n",
    "        # read through the test data BED file and load in\n",
    "        # coordinates for each example into memory,\n",
    "        # ***IF*** the example is NOT bound\n",
    "        coords = []\n",
    "        line_count = 0\n",
    "        with open(self.valfile) as f:\n",
    "            for line in f:\n",
    "                line_split = line.rstrip().split()\n",
    "                # if example is bound, value in last column is 1;\n",
    "                # else it is 0\n",
    "                if line_split[-1] == \"0\":  # if unbound\n",
    "                    if skip is None or line_count % skip == 0:\n",
    "                        coords.append(line_split[:3])\n",
    "                    line_count += 1\n",
    "        self.coords = [Coordinates(c[0], int(c[1]), int(c[2])) for c in coords]\n",
    "\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "        # convert a batch's worth of coordinates into one-hot sequences\n",
    "        batch = self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        return self.converter(batch)\n",
    "\n",
    "        \n",
    "class BoundTestGenerator(Sequence):\n",
    "    # This generator retrieves all coordinates for ***BOUND*** windows\n",
    "    # in the test set, converting their sequence to one-hot encodings.\n",
    "\n",
    "\n",
    "    def __init__(self, batchsize, val_file):\n",
    "        self.valfile = val_file\n",
    "        self.get_steps(batchsize)\n",
    "        # the plots we're making are for the human test data only\n",
    "        assert \"hg38\" in val_file\n",
    "        self.converter = PyfaidxCoordsToVals(GENOMES[\"hg38\"])\n",
    "        # batchsize here is just how many examples to evaluate at once,\n",
    "        # not the training batchsize; go a high as your GPU can fit\n",
    "        self.batchsize = batchsize\n",
    "        self.get_bound_coords()\n",
    "        \n",
    "        \n",
    "    def get_steps(self, batchsize):\n",
    "        # calculates the number of steps needed to get through\n",
    "        # all batches of BOUND examples\n",
    "        # (Keras predict_generator code needs to know this)\n",
    "        with open(self.valfile) as f:\n",
    "            # if condition tests that the example is bound\n",
    "            lines_in_file = sum([1 for line in f if line.rstrip().split()[-1] == \"1\"])\n",
    "        self.steps = lines_in_file // batchsize\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    \n",
    "        \n",
    "    def get_bound_coords(self):\n",
    "        # read through the test data BED file and load in\n",
    "        # coordinates for each example into memory,\n",
    "        # ***IF*** the example is BOUND\n",
    "        with open(self.valfile) as f:\n",
    "            # if example is bound, value in last column is 1;\n",
    "            # else it is 0\n",
    "            coords_tmp = [line.split()[:3] for line in f if line.rstrip().split()[-1] == \"1\"]\n",
    "            self.coords = [Coordinates(c[0], int(c[1]), int(c[2])) for c in coords_tmp]\n",
    "            assert len(coords_tmp) > 0\n",
    "\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "        # convert a batch's worth of coordinates into one-hot sequences\n",
    "        batch = self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        assert len(batch) > 0\n",
    "        return self.converter(batch)\n",
    "    \n",
    "\n",
    "def get_preds_batched_fast(model, batch_size, bound, val_file, skip = None):\n",
    "    # Make predictions on test data using a specified model.\n",
    "    # Batch_size can be as big as your compute can handle.\n",
    "    # Different generators are used for bound/unbound sites to\n",
    "    # to simplify downstream analysis (Alu site plots are made\n",
    "    # for unbound sites only).\n",
    "    \n",
    "    # NOTE the use of SKIP here for the unbound site generator --\n",
    "    # needs to be consistent everywhere in this notebook!\n",
    "    if bound:\n",
    "        generator = BoundTestGenerator(batch_size, val_file)\n",
    "    else:\n",
    "        generator = UnboundTestGenerator(batch_size, val_file, skip)\n",
    "    return np.squeeze(model.predict_generator(generator,\n",
    "                                              use_multiprocessing = True,\n",
    "                                              workers = 4, verbose = 1))\n",
    "\n",
    "\n",
    "def get_avg_preds_on_seqs(models, bound, val_file, DA = False, skip = None):\n",
    "    # Generate predictions on test data for a set of models,\n",
    "    # and then compute the average prediction across models\n",
    "    # for each example in the test data.\n",
    "    \n",
    "    all_preds = [get_preds_batched_fast(model, 1024, bound, val_file, skip = skip) for model in models]\n",
    "    avg_preds = np.mean(np.array(all_preds), axis = 0)\n",
    "    if DA:\n",
    "        # DA models return 2 predictions: 1 for the binding task,\n",
    "        # and 1 for the species discriminator task.\n",
    "        # We only want the binding task predictions\n",
    "        avg_preds = avg_preds[0]\n",
    "    return avg_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File and Model Loading\n",
    "\n",
    "\n",
    "def get_alu_intersect_file_chr2():\n",
    "    # See make_repeat_files.sh for creating this file.\n",
    "    # Basically:\n",
    "    # awk '$1 == \"chr2\"' [repeatmaker alu file] > rmsk_alus_chr2.bed\n",
    "    # bedtools intersect -a [get_test_bed_file(species)] -b rmsk_alus_chr2.bed -u -sorted > chr2_alus_intersect.bed\n",
    "    \n",
    "    # This file should contain all windows in the test data\n",
    "    # that intersect with Alus (this is different from all\n",
    "    # annotated Alus -- model is expecting windows of the\n",
    "    # correct size).\n",
    "    \n",
    "    # This file is not specific to a TF.\n",
    "    return(ROOT + \"data/hg38/chr2_alus_intersect.bed\")\n",
    "\n",
    "\n",
    "def get_model_file(tf, train_species, run = 1, model_type = MODEL_TYPE):\n",
    "    # This function returns the filepath where the model for a given\n",
    "    # TF, training species, and run is saved.\n",
    "    # By default, the file for the best model across all training epochs\n",
    "    # is returned, you can change model_type to select the last model instead.\n",
    "    # This function specifically looks for the most recent model file,\n",
    "    # if there are multiple for the same run-TF-species combo.\n",
    "    try:\n",
    "        run_int = int(run)\n",
    "    except:\n",
    "        print(\"Error: You need to pass in a run number.\")\n",
    "    \n",
    "    model_file_prefix = ROOT + \"/\".join([\"models\", tf, train_species + \"_trained\", \"basic_model/\"])\n",
    "    \n",
    "    if train_species == \"DA\":\n",
    "        model_file_prefix = model_file_prefix.replace(\"DA\", \"mm10\")  # assuming all DA models are mouse-trained\n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"DA\")\n",
    "    if train_species == \"NS\":\n",
    "        model_file_prefix = model_file_prefix.replace(\"NS\", \"hg38\")\n",
    "        model_file_prefix = model_file_prefix.replace(\"basic_model\", \"basic_model_nosines\")\n",
    "        \n",
    "    # leftover from when I tried early stopping models instead\n",
    "    if model_type == \"end\":\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_15E_end.model\"\n",
    "    elif model_type == \"earlystop\":\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_earlystop.model\"\n",
    "    elif model_type == \"best\":\n",
    "        model_file_suffix = \"_run\" + str(run) + \"_best.model\"\n",
    "    else:\n",
    "        assert model_type is None, model_type\n",
    "    \n",
    "    files = [f for f in os.listdir(model_file_prefix) if f.endswith(model_file_suffix)]\n",
    "    if len(files) == 1:\n",
    "        return model_file_prefix + files[0]\n",
    "    # sort files and return the one that is most recent\n",
    "    latest_file = max([model_file_prefix + f for f in files], key=os.path.getctime)\n",
    "    print(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "def load_keras_model(model_file, DA = False):\n",
    "    if DA:\n",
    "        return keras.models.load_model(model_file,\n",
    "                    custom_objects = {\"GradientReversal\":GradientReversal,\n",
    "                                      \"custom_loss\":custom_loss})\n",
    "    return keras.models.load_model(model_file)\n",
    "\n",
    "\n",
    "def get_models_all_runs(tf, train_species):\n",
    "    # load in models for all runs, for a given TF and training species\n",
    "    # returns a list of Keras model objects\n",
    "    files = [get_model_file(tf, train_species, run + 1) for run in range(5)]\n",
    "    if train_species == \"DA\":\n",
    "        return [load_keras_model(f, DA = True) for f in files]\n",
    "    else:\n",
    "        return [load_keras_model(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alu functions\n",
    "\n",
    "def get_window_starts(bed_file, skip = None):\n",
    "    # This function reads in a BED file and returns a list of\n",
    "    # the value in column 2 for every line.\n",
    "    # If \"skip\" is none, this is equivalent to: awk '{print $2}'\n",
    "    # If \"skip\" is NOT None, only every skip-th ***UNBOUND***\n",
    "    # line will be retained.\n",
    "    # Note that the filtering out of bound sites only\n",
    "    # happens if skip is not None.\n",
    "    # This function is intended for use only in analysis of\n",
    "    # UNBOUND windows that may overlap with Alus. Modify before\n",
    "    # using this for bound site analysis.\n",
    "    window_starts = []\n",
    "    line_count = 0\n",
    "    with open(bed_file) as f:\n",
    "        for line in f:\n",
    "            line_split = line.rstrip().split()\n",
    "            if skip is None:\n",
    "                # if skip is None, we will read in every line,\n",
    "                # no matter what\n",
    "                window_starts.append(int(line_split[1]))\n",
    "            elif line_split[-1] == \"0\":\n",
    "                # if skip is not None, we will only keep\n",
    "                # every skip-th UNBOUND line (ending in 0)\n",
    "                if line_count % skip == 0:\n",
    "                    window_starts.append(int(line_split[1]))\n",
    "                line_count += 1\n",
    "    return window_starts\n",
    "\n",
    "\n",
    "def matches_across_sorted_lists(list_a, list_b):\n",
    "    # This function takes in 2 SORTED lists of integers\n",
    "    # and returns a boolean array the length of list_a,\n",
    "    # where the entry at index i = list_a[i] in list_b\n",
    "    matches = []\n",
    "    b_index = 0\n",
    "    for a_item in list_a:\n",
    "        while True:\n",
    "            if b_index >= len(list_b):\n",
    "                matches.append(False)\n",
    "                break\n",
    "            if list_b[b_index] > a_item:\n",
    "                matches.append(False)\n",
    "                break\n",
    "            elif list_b[b_index] == a_item:\n",
    "                matches.append(True)\n",
    "                b_index += 1\n",
    "                break\n",
    "            else:\n",
    "                b_index += 1\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_alu_intersect(tf, skip = None):\n",
    "    # This function generates binary labels for every example\n",
    "    # in the test set, indicating whether or not that window\n",
    "    # intersects with an annotated Alu element. The code for\n",
    "    # doing this has been streamlined, because:\n",
    "    # 1. The file returned by get_alu_intersect_file_chr2()\n",
    "    #    already contains all in the test set that intersect \n",
    "    #    with annotated Alus (generated by bedtools intersect).\n",
    "    # 2. We can uniquely identify windows by their start coordinate\n",
    "    #    only, since all test examples are from the same chromosome.\n",
    "    #\n",
    "    # Thus, the process is:\n",
    "    # 1. Load in (sorted) window starts for each test example\n",
    "    # 2. Load in (sorted) window starts for each test example that\n",
    "    #        overlaps with an annotated Alu\n",
    "    # 3. Create boolean vector, the same length as the result of #1,\n",
    "    #        indicating if each example in #1 is also in #2\n",
    "    #\n",
    "    # For #3, we take advantage of the fact that the window start\n",
    "    # lists are already sorted and use a more efficient algorithm\n",
    "    # than just \"[start_coord in #2 for start_coord in #1]\"\n",
    "    \n",
    "    # Step 1\n",
    "    test_bed = get_test_bed_file(\"hg38\", tf)\n",
    "    test_windows = get_window_starts(test_bed, skip)\n",
    "    # Step 2\n",
    "    alu_intersect_bed = get_alu_intersect_file_chr2()\n",
    "    alu_windows = get_window_starts(alu_intersect_bed, None)\n",
    "    # Step 3\n",
    "    return matches_across_sorted_lists(test_windows, alu_windows)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CTCF =====\n",
      "\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/basic_model/2020-08-12_16-21-33_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/basic_model/2020-08-12_17-16-29_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/basic_model/2020-08-12_18-11-29_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/basic_model/2020-08-12_19-06-35_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/basic_model/2020-08-12_20-01-19_run5_best.model\n",
      "Predicting on bound sequences with mm10-trained models...\n",
      "24/24 [==============================] - 15s 614ms/step\n",
      "24/24 [==============================] - 3s 144ms/step\n",
      "24/24 [==============================] - 3s 128ms/step\n",
      "24/24 [==============================] - 3s 126ms/step\n",
      "24/24 [==============================] - 3s 134ms/step\n",
      "Predicting on unbound sequences with mm10-trained models...\n",
      "21/21 [==============================] - 3s 139ms/step\n",
      "21/21 [==============================] - 3s 133ms/step\n",
      "21/21 [==============================] - 3s 151ms/step\n",
      "21/21 [==============================] - 3s 138ms/step\n",
      "21/21 [==============================] - 3s 138ms/step\n",
      "21/21 [==============================] - 3s 131ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/DA/2020-08-13_16-49-49_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/DA/2020-08-15_01-13-00_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/DA/2020-08-15_04-27-01_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/DA/2020-08-15_07-44-34_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/mm10_trained/DA/2020-08-15_11-02-40_run5_best.model\n",
      "Predicting on bound sequences with DA-trained models...\n",
      "24/24 [==============================] - 3s 136ms/step\n",
      "24/24 [==============================] - 3s 143ms/step\n",
      "24/24 [==============================] - 3s 133ms/step\n",
      "24/24 [==============================] - 3s 129ms/step\n",
      "24/24 [==============================] - 3s 140ms/step\n",
      "Predicting on unbound sequences with DA-trained models...\n",
      "21/21 [==============================] - 3s 140ms/step\n",
      "21/21 [==============================] - 3s 131ms/step\n",
      "21/21 [==============================] - 3s 133ms/step\n",
      "21/21 [==============================] - 3s 138ms/step\n",
      "21/21 [==============================] - 3s 149ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model/2020-08-12_13-50-05_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model/2020-08-12_14-45-35_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model/2020-08-12_15-40-06_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model/2020-08-12_16-34-37_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model/2020-08-12_17-29-35_run5_best.model\n",
      "Predicting on bound sequences with hg38-trained models...\n",
      "24/24 [==============================] - 3s 142ms/step\n",
      "24/24 [==============================] - 3s 131ms/step\n",
      "24/24 [==============================] - 3s 136ms/step\n",
      "24/24 [==============================] - 3s 129ms/step\n",
      "24/24 [==============================] - 3s 126ms/step\n",
      "Predicting on unbound sequences with hg38-trained models...\n",
      "21/21 [==============================] - 3s 148ms/step\n",
      "21/21 [==============================] - 3s 150ms/step\n",
      "21/21 [==============================] - 3s 150ms/step\n",
      "21/21 [==============================] - 3s 136ms/step\n",
      "21/21 [==============================] - 3s 149ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CTCF/hg38_trained/basic_model_nosines/2020-08-10_00-38-37_run1_best.model\n",
      "Predicting on bound sequences with NS-trained models...\n",
      "24/24 [==============================] - 4s 151ms/step\n",
      "24/24 [==============================] - 3s 137ms/step\n",
      "24/24 [==============================] - 3s 143ms/step\n",
      "24/24 [==============================] - 4s 162ms/step\n",
      "24/24 [==============================] - 4s 148ms/step\n",
      "Predicting on unbound sequences with NS-trained models...\n",
      "21/21 [==============================] - 3s 141ms/step\n",
      "21/21 [==============================] - 3s 162ms/step\n",
      "21/21 [==============================] - 3s 138ms/step\n",
      "21/21 [==============================] - 3s 154ms/step\n",
      "21/21 [==============================] - 3s 143ms/step\n",
      "\n",
      "===== CEBPA =====\n",
      "\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/mm10_trained/basic_model/2020-08-12_20-55-52_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/mm10_trained/basic_model/2020-08-12_22-06-09_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/mm10_trained/basic_model/2020-08-12_23-16-31_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/mm10_trained/basic_model/2020-08-13_00-27-23_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/mm10_trained/basic_model/2020-08-13_01-38-15_run5_best.model\n",
      "Predicting on bound sequences with mm10-trained models...\n",
      "25/25 [==============================] - 3s 135ms/step\n",
      "25/25 [==============================] - 3s 135ms/step\n",
      "25/25 [==============================] - 3s 139ms/step\n",
      "25/25 [==============================] - 3s 132ms/step\n",
      "25/25 [==============================] - 3s 133ms/step\n",
      "Predicting on unbound sequences with mm10-trained models...\n",
      "21/21 [==============================] - 3s 139ms/step\n",
      "21/21 [==============================] - 3s 149ms/step\n",
      "21/21 [==============================] - 3s 145ms/step\n",
      "21/21 [==============================] - 3s 141ms/step\n",
      "21/21 [==============================] - 3s 157ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with DA-trained models...\n",
      "25/25 [==============================] - 4s 146ms/step\n",
      "25/25 [==============================] - 3s 132ms/step\n",
      "25/25 [==============================] - 3s 137ms/step\n",
      "25/25 [==============================] - 4s 144ms/step\n",
      "25/25 [==============================] - 3s 134ms/step\n",
      "Predicting on unbound sequences with DA-trained models...\n",
      "21/21 [==============================] - 3s 147ms/step\n",
      "21/21 [==============================] - 3s 148ms/step\n",
      "21/21 [==============================] - 3s 145ms/step\n",
      "21/21 [==============================] - 3s 143ms/step\n",
      "21/21 [==============================] - 3s 144ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/hg38_trained/basic_model/2020-08-12_18-25-15_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/hg38_trained/basic_model/2020-08-12_19-18-48_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/hg38_trained/basic_model/2020-08-12_20-12-20_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/hg38_trained/basic_model/2020-08-12_21-05-45_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/CEBPA/hg38_trained/basic_model/2020-08-12_21-59-01_run5_best.model\n",
      "Predicting on bound sequences with hg38-trained models...\n",
      "25/25 [==============================] - 4s 143ms/step\n",
      "25/25 [==============================] - 3s 132ms/step\n",
      "25/25 [==============================] - 4s 141ms/step\n",
      "25/25 [==============================] - 4s 145ms/step\n",
      "25/25 [==============================] - 4s 150ms/step\n",
      "Predicting on unbound sequences with hg38-trained models...\n",
      "21/21 [==============================] - 3s 146ms/step\n",
      "21/21 [==============================] - 3s 140ms/step\n",
      "21/21 [==============================] - 3s 144ms/step\n",
      "21/21 [==============================] - 3s 144ms/step\n",
      "21/21 [==============================] - 3s 133ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with NS-trained models...\n",
      "25/25 [==============================] - 3s 136ms/step\n",
      "25/25 [==============================] - 3s 132ms/step\n",
      "25/25 [==============================] - 3s 131ms/step\n",
      "25/25 [==============================] - 3s 130ms/step\n",
      "25/25 [==============================] - 3s 136ms/step\n",
      "Predicting on unbound sequences with NS-trained models...\n",
      "21/21 [==============================] - 3s 141ms/step\n",
      "21/21 [==============================] - 3s 163ms/step\n",
      "21/21 [==============================] - 3s 147ms/step\n",
      "21/21 [==============================] - 3s 158ms/step\n",
      "21/21 [==============================] - 3s 148ms/step\n",
      "\n",
      "===== Hnf4a =====\n",
      "\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/mm10_trained/basic_model/2020-08-13_02-49-26_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/mm10_trained/basic_model/2020-08-13_03-50-35_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/mm10_trained/basic_model/2020-08-13_04-51-42_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/mm10_trained/basic_model/2020-08-13_05-52-28_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/mm10_trained/basic_model/2020-08-13_06-53-50_run5_best.model\n",
      "Predicting on bound sequences with mm10-trained models...\n",
      "31/31 [==============================] - 4s 128ms/step\n",
      "31/31 [==============================] - 5s 156ms/step\n",
      "31/31 [==============================] - 4s 142ms/step\n",
      "31/31 [==============================] - 4s 137ms/step\n",
      "31/31 [==============================] - 4s 119ms/step\n",
      "Predicting on unbound sequences with mm10-trained models...\n",
      "20/20 [==============================] - 3s 136ms/step\n",
      "20/20 [==============================] - 3s 144ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "20/20 [==============================] - 3s 151ms/step\n",
      "20/20 [==============================] - 3s 132ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with DA-trained models...\n",
      "31/31 [==============================] - 4s 130ms/step\n",
      "31/31 [==============================] - 4s 140ms/step\n",
      "31/31 [==============================] - 4s 124ms/step\n",
      "31/31 [==============================] - 4s 125ms/step\n",
      "31/31 [==============================] - 4s 126ms/step\n",
      "Predicting on unbound sequences with DA-trained models...\n",
      "20/20 [==============================] - 3s 164ms/step\n",
      "20/20 [==============================] - 3s 132ms/step\n",
      "20/20 [==============================] - 3s 147ms/step\n",
      "20/20 [==============================] - 3s 143ms/step\n",
      "20/20 [==============================] - 3s 143ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/hg38_trained/basic_model/2020-08-12_22-53-25_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/hg38_trained/basic_model/2020-08-12_23-51-55_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/hg38_trained/basic_model/2020-08-13_00-50-17_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/hg38_trained/basic_model/2020-08-13_01-49-16_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/Hnf4a/hg38_trained/basic_model/2020-08-13_02-47-56_run5_best.model\n",
      "Predicting on bound sequences with hg38-trained models...\n",
      "31/31 [==============================] - 4s 124ms/step\n",
      "31/31 [==============================] - 4s 130ms/step\n",
      "31/31 [==============================] - 4s 136ms/step\n",
      "31/31 [==============================] - 4s 132ms/step\n",
      "31/31 [==============================] - 4s 130ms/step\n",
      "Predicting on unbound sequences with hg38-trained models...\n",
      "20/20 [==============================] - 3s 151ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with NS-trained models...\n",
      "31/31 [==============================] - 4s 134ms/step\n",
      "31/31 [==============================] - 4s 132ms/step\n",
      "31/31 [==============================] - 4s 124ms/step\n",
      "31/31 [==============================] - 4s 126ms/step\n",
      "31/31 [==============================] - 4s 127ms/step\n",
      "Predicting on unbound sequences with NS-trained models...\n",
      "20/20 [==============================] - 3s 137ms/step\n",
      "20/20 [==============================] - 3s 138ms/step\n",
      "20/20 [==============================] - 3s 135ms/step\n",
      "20/20 [==============================] - 3s 145ms/step\n",
      "20/20 [==============================] - 3s 138ms/step\n",
      "\n",
      "===== RXRA =====\n",
      "\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/mm10_trained/basic_model/2020-08-13_07-55-05_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/mm10_trained/basic_model/2020-08-13_08-58-17_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/mm10_trained/basic_model/2020-08-13_10-00-46_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/mm10_trained/basic_model/2020-08-13_11-03-22_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/mm10_trained/basic_model/2020-08-13_12-07-02_run5_best.model\n",
      "Predicting on bound sequences with mm10-trained models...\n",
      "67/67 [==============================] - 9s 138ms/step\n",
      "67/67 [==============================] - 9s 128ms/step\n",
      "67/67 [==============================] - 8s 120ms/step\n",
      "67/67 [==============================] - 8s 118ms/step\n",
      "67/67 [==============================] - 8s 124ms/step\n",
      "Predicting on unbound sequences with mm10-trained models...\n",
      "20/20 [==============================] - 3s 139ms/step\n",
      "20/20 [==============================] - 3s 136ms/step\n",
      "20/20 [==============================] - 3s 138ms/step\n",
      "20/20 [==============================] - 3s 139ms/step\n",
      "20/20 [==============================] - 3s 143ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with DA-trained models...\n",
      "67/67 [==============================] - 9s 127ms/step\n",
      "67/67 [==============================] - 8s 120ms/step\n",
      "67/67 [==============================] - 8s 122ms/step\n",
      "67/67 [==============================] - 8s 117ms/step\n",
      "67/67 [==============================] - 8s 120ms/step\n",
      "Predicting on unbound sequences with DA-trained models...\n",
      "20/20 [==============================] - 3s 142ms/step\n",
      "20/20 [==============================] - 3s 140ms/step\n",
      "20/20 [==============================] - 3s 138ms/step\n",
      "20/20 [==============================] - 3s 137ms/step\n",
      "20/20 [==============================] - 3s 143ms/step\n",
      "Loading models...\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/hg38_trained/basic_model/2020-08-13_03-46-14_run1_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/hg38_trained/basic_model/2020-08-13_05-10-50_run2_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/hg38_trained/basic_model/2020-08-13_06-36-12_run3_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/hg38_trained/basic_model/2020-08-13_08-01-33_run4_best.model\n",
      "/users/kcochran/projects/domain_adaptation/models/RXRA/hg38_trained/basic_model/2020-08-13_09-26-45_run5_best.model\n",
      "Predicting on bound sequences with hg38-trained models...\n",
      "67/67 [==============================] - 8s 123ms/step\n",
      "67/67 [==============================] - 8s 119ms/step\n",
      "67/67 [==============================] - 8s 120ms/step\n",
      "67/67 [==============================] - 8s 122ms/step\n",
      "67/67 [==============================] - 8s 120ms/step\n",
      "Predicting on unbound sequences with hg38-trained models...\n",
      "20/20 [==============================] - 3s 141ms/step\n",
      "20/20 [==============================] - 3s 146ms/step\n",
      "20/20 [==============================] - 3s 130ms/step\n",
      "20/20 [==============================] - 3s 142ms/step\n",
      "20/20 [==============================] - 3s 147ms/step\n",
      "Loading models...\n",
      "Predicting on bound sequences with NS-trained models...\n",
      "67/67 [==============================] - 8s 124ms/step\n",
      "67/67 [==============================] - 8s 122ms/step\n",
      "67/67 [==============================] - 8s 116ms/step\n",
      "67/67 [==============================] - 8s 124ms/step\n",
      "67/67 [==============================] - 8s 123ms/step\n",
      "Predicting on unbound sequences with NS-trained models...\n",
      "20/20 [==============================] - 3s 140ms/step\n",
      "20/20 [==============================] - 3s 140ms/step\n",
      "20/20 [==============================] - 3s 139ms/step\n",
      "20/20 [==============================] - 3s 139ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "# This cell takes a while to run. To decrease time, increase SKIP.\n",
    "\n",
    "preds_dict = defaultdict(lambda: defaultdict(lambda: dict()))\n",
    "\n",
    "for tf in tfs:\n",
    "    print(\"\\n=====\", tf, \"=====\\n\")\n",
    "    \n",
    "    # get filename for test data\n",
    "    val_file = get_test_bed_file(\"hg38\", tf)\n",
    "    \n",
    "    # for each model type...\n",
    "    for train_species in all_trainspecies:\n",
    "        print(\"Loading models...\")\n",
    "        models = get_models_all_runs(tf, train_species)\n",
    "    \n",
    "        print(\"Predicting on bound sequences with \" + train_species + \"-trained models...\")\n",
    "        preds_dict[\"bound\"][tf][train_species] = get_avg_preds_on_seqs(models, True, val_file,\n",
    "                                                                       DA = train_species == \"DA\")\n",
    "        print(\"Predicting on unbound sequences with \" + train_species + \"-trained models...\")\n",
    "        preds_dict[\"unbound\"][tf][train_species] = get_avg_preds_on_seqs(models, False, val_file,\n",
    "                                                                         DA = train_species == \"DA\",\n",
    "                                                                        skip = SKIP)\n",
    "        # clear memory to reduce unnecessary consumption\n",
    "        del train_species, models\n",
    "        keras.backend.clear_session()\n",
    "del tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot functions\n",
    "\n",
    "def bound_scatterplot(model1_preds, model2_preds, tf_name,\n",
    "                      plot_index, model_names):\n",
    "    # This function draws a single scatterplot of bound sites (subplot of figure).\n",
    "    # model1_preds: x-axis values for all points to plot\n",
    "    # model2_preds: y-axis values for all points to plot\n",
    "    # plot_index: either 0 or 1. 0 = top plot in column, 1 = bottom plot.\n",
    "    # model_names: plot-acceptable names for the models that generated the x-axis\n",
    "    #     and y-axis predictions, respectively. Expecting a list of length 2.\n",
    "    \n",
    "    # First, a random sample of sites are chosen, so that\n",
    "    # the plot is not too overcrowded\n",
    "    model_preds_subsample = random.sample(list(zip(model1_preds, model2_preds)),\n",
    "                            k = int(len(model1_preds) / BOUND_SUBSAMPLE_RATE))\n",
    "    model1_preds_subsample = [pair[0] for pair in model_preds_subsample]\n",
    "    model2_preds_subsample = [pair[1] for pair in model_preds_subsample]\n",
    "    \n",
    "    # Then each bound site is plotted as an individual dot on a scatter plot\n",
    "    plt.scatter(model1_preds_subsample, model2_preds_subsample,\n",
    "                alpha = ALPHA, s = DOT_SIZE, c = \"#007DEA\")\n",
    "    \n",
    "    # adjust axes to show all points, add ticks\n",
    "    plt.xlim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.ylim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.xticks([0, 0.5, 1])\n",
    "    plt.yticks([0, 0.5, 1])\n",
    "    \n",
    "    # add axis labels\n",
    "    plt.ylabel(model_names[1] + \" Model Prediction\", fontsize = AXIS_SIZE)\n",
    "    # add x-axis label only if this subplot is the bottom row of the figure\n",
    "    if plot_index == len(tfs) - 1:\n",
    "        if len(model_names[0]) > 5:  # adjust fontsize for longer model names\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE - 1)\n",
    "        else:\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE)\n",
    "        \n",
    "    # add second \"axis\" to write TF name to the left of the plot\n",
    "    # only do this for bound scatterplots because they are in left column of figure\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.spines[\"left\"].set_position((\"axes\", 0 - TF_TWINAX_OFFSET))\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "    ax2.yaxis.set_ticks_position('none')\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_ylabel(tf_name, fontsize = AXIS_SIZE + 2)\n",
    "    \n",
    "    # add text above subplot only if we are drawing in the top row of the figure\n",
    "    if plot_index == 0:\n",
    "        ax3 = plt.gca().twiny()\n",
    "        ax3.spines[\"top\"].set_position((\"axes\", 1))\n",
    "        ax3.set_xticklabels([])\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_xlabel(\"Bound Sites\", fontsize = AXIS_SIZE + 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "def unbound_scatterplot(model1_preds, model2_preds,\n",
    "                        plot_index, model_names):\n",
    "    # This function draws a single scatterplot of unbound sites.\n",
    "    # model1_preds: x-axis values for all points to plot\n",
    "    # model2_preds: y-axis values for all points to plot\n",
    "    # plot_index: either 0 or 1. 0 = top plot in column, 1 = bottom plot.\n",
    "    # model_names: plot-acceptable names for the models that generated the x-axis\n",
    "    #     and y-axis predictions, respectively. Expecting a list of length 2.\n",
    "    \n",
    "    # no subsampling here, as in bound_scatterplot(),\n",
    "    # because we already subsampled unbound sites using SKIP\n",
    "    plt.scatter(model1_preds, model2_preds, alpha = ALPHA, s = DOT_SIZE, c = \"#D60242\")\n",
    "    \n",
    "    # adjust axes\n",
    "    plt.xlim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.ylim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.xticks([0, 0.5, 1])\n",
    "    \n",
    "    # label x-axis only if we are drawing subplot in bottom row of figure\n",
    "    if plot_index == len(tfs) - 1:\n",
    "        if len(model_names[0]) > 5:  # adjust fontsize for longer model names\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE - 1)\n",
    "        else:\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE)\n",
    "        \n",
    "    # add text above subplot only if we are drawing in the top row of the figure\n",
    "    if plot_index == 0:\n",
    "        ax2 = plt.gca().twiny()\n",
    "        ax2.spines[\"top\"].set_position((\"axes\", 1))\n",
    "        ax2.set_xticklabels([])\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_xlabel(\"Unbound Sites\", fontsize = AXIS_SIZE + 2)\n",
    "\n",
    "        \n",
    "        \n",
    "def generate_bound_unbound_scatters(preds_dict, train_species,\n",
    "                                    save_files = False):\n",
    "    # This function generates the full Figure 4,7, or 10 (bound and unbound sites).\n",
    "    # preds_dict: a 3-layer dictionary, where keys for layer 1 are [\"bound\", \"unbound\"],\n",
    "    #     keys for layer 2 are TF names, and keys for layer 3 are model type / species\n",
    "    #     names ([\"mm10\", \"DA\", \"hg38\"]).\n",
    "    # train_species: a list of length 2 containing the model type / species names for\n",
    "    #     the model predictions to plot on the x and y axes, respectively. Will be used\n",
    "    #     to index into layer 3 of preds_dict.\n",
    "    \n",
    "    assert len(train_species) == 2, train_speies\n",
    "    \n",
    "    # translate short-hand model type names for plot-acceptable names\n",
    "    model_names = [model_names_dict[string] for string in train_species]\n",
    "\n",
    "    # setup subplots: two columns (1 for bound sites, 1 for unbound, 4 rows (1 per TF)\n",
    "    mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "    fig, ax = plt.subplots(nrows = len(tfs), ncols = 2, figsize = FIG_SIZE_2_by_4,\n",
    "                           sharex = True, sharey = True,\n",
    "                           gridspec_kw = {'hspace': 0.08, 'wspace': 0.13})\n",
    "\n",
    "    # iterate over rows of subplots\n",
    "    for plot_index,tf in enumerate(tfs):\n",
    "        # left subplot in this row will be for bound sites\n",
    "        plt.sca(ax[plot_index][0])\n",
    "        bound_scatterplot(preds_dict[\"bound\"][tf][train_species[0]],\n",
    "                          preds_dict[\"bound\"][tf][train_species[1]],\n",
    "                          tfs_latex_names[plot_index], plot_index, model_names)\n",
    "\n",
    "        # right subplot in this row will be for unbound sites\n",
    "        plt.sca(ax[plot_index][1])\n",
    "        unbound_scatterplot(preds_dict[\"unbound\"][tf][train_species[0]],\n",
    "                            preds_dict[\"unbound\"][tf][train_species[1]],\n",
    "                            plot_index, model_names)\n",
    "    \n",
    "    if not save_files:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(ROOT + \"plots/scatter_\" + train_species[0] + \"_\" + train_species[1] + \".pdf\",\n",
    "                    bbox_inches='tight', pad_inches = 0)\n",
    "        plt.savefig(ROOT + \"plots/scatter_\" + train_species[0] + \"_\" + train_species[1] + \".png\",\n",
    "                    bbox_inches='tight', pad_inches = 0)\n",
    "        \n",
    "\n",
    "        \n",
    "def alu_unbound_scatterplot(model1_preds, model2_preds, tf_name, plot_index, model_names):\n",
    "    # This function draws one scatterplot of unbound Alu windows.\n",
    "    # model1_preds: x-axis values for all points to plot\n",
    "    # model2_preds: y-axis values for all points to plot\n",
    "    # plot_index: either 0 or 1. 0 = top plot in column, 1 = bottom plot.\n",
    "    # model_names: plot-acceptable names for the models that generated the x-axis\n",
    "    #     and y-axis predictions, respectively. Expecting a list of length 2.\n",
    "    \n",
    "    plt.scatter(model1_preds, model2_preds, alpha = ALPHA, s = DOT_SIZE, c = \"#D60242\")\n",
    "    plt.xlim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.ylim(0 - AX_OFFSET, 1 + AX_OFFSET)\n",
    "    plt.xticks([0, 0.5, 1])\n",
    "    plt.yticks([0, 0.5, 1])\n",
    "    plt.ylabel(model_names[1] + \" Model Prediction\", fontsize = AXIS_SIZE)\n",
    "    \n",
    "    # if plot_index is 1, we are at the bottom row in this column of subplots\n",
    "    # so we should add the x-axis label\n",
    "    if plot_index == len(tfs) // 2 - 1:\n",
    "        if len(model_names[0]) > 5:\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE - 1)\n",
    "        else:\n",
    "            plt.xlabel(model_names[0] + \" Model Prediction\", fontsize = AXIS_SIZE)\n",
    "    \n",
    "    # this second axis is actually the TF name on the left of the normal y-axis label\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.spines[\"left\"].set_position((\"axes\", 0 - TF_TWINAX_OFFSET))\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "    ax2.yaxis.set_ticks_position('none')\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_ylabel(tf_name, fontsize = AXIS_SIZE + 2)\n",
    "    \n",
    "    # if we are at the top subplot in the column, add the column \"title\" above\n",
    "    if plot_index == 0:\n",
    "        ax2 = plt.gca().twiny()\n",
    "        ax2.spines[\"top\"].set_position((\"axes\", 1))\n",
    "        ax2.set_xticklabels([])\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_xlabel(\"Unbound \" + r\"$\\bf{Alus}$\", fontsize = AXIS_SIZE + 2)\n",
    "        \n",
    "        \n",
    "# run twice, to get 2 x 2 for 4 TFs\n",
    "# once with tf_split_half = 1 and once with tf_split_half = 2\n",
    "def generate_unbound_alu_scatters(preds_dict, train_species, tf_split_half = 1,\n",
    "                                  skip = None, save_files = False):\n",
    "    # This function generates half of the plot shown in Figures 5 and 11.\n",
    "    # if tf_split_half = 1, the left half of the plot is drawn; if 2, the right half.\n",
    "    # preds_dict: a 3-layer dictionary, where keys for layer 1 are [\"bound\", \"unbound\"],\n",
    "    #     keys for layer 2 are TF names, and keys for layer 3 are model type / species\n",
    "    #     names ([\"mm10\", \"DA\", \"hg38\"]).\n",
    "    # train_species: a list of length 2 containing the model type / species names for\n",
    "    #     the model predictions to plot on the x and y axes, respectively. Will be used\n",
    "    #     to index into layer 3 of preds_dict.\n",
    "    # skip here should correspond to the skip argument used elsewhere in the code.\n",
    "    \n",
    "    \n",
    "    model_names = [model_names_dict[string] for string in train_species]\n",
    "    \n",
    "    mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "    # create a plot with 2 rows and 1 column of subplots\n",
    "    fig, ax = plt.subplots(nrows = len(tfs) // 2, ncols = 1, figsize = FIG_SIZE_1_by_2,\n",
    "                           sharex = True, gridspec_kw = {'hspace': 0.08})\n",
    "\n",
    "    # generate the \"left half\" of the full 2x2 plot\n",
    "    if tf_split_half == 1:\n",
    "        for plot_index,tf in enumerate(tfs[:2]):\n",
    "            alu_labels = get_alu_intersect(tf, skip = skip)\n",
    "            num_preds = len(preds_dict[\"unbound\"][tf][train_species[0]])\n",
    "            alu_labels = alu_labels[:num_preds]\n",
    "            plt.sca(ax[plot_index])\n",
    "            alu_unbound_scatterplot(np.array(preds_dict[\"unbound\"][tf][train_species[0]])[alu_labels],\n",
    "                                    np.array(preds_dict[\"unbound\"][tf][train_species[1]])[alu_labels],\n",
    "                                    tfs_latex_names[plot_index], plot_index, model_names)\n",
    "    \n",
    "    # generate the \"right half\" of the full 2x2 plot\n",
    "    else:\n",
    "        for plot_index,tf in enumerate(tfs[2:]):\n",
    "            alu_labels = get_alu_intersect(tf, skip = skip)\n",
    "            num_preds = len(preds_dict[\"unbound\"][tf][train_species[0]])\n",
    "            alu_labels = alu_labels[:num_preds]\n",
    "            plt.sca(ax[plot_index])\n",
    "            alu_unbound_scatterplot(np.array(preds_dict[\"unbound\"][tf][train_species[0]])[alu_labels],\n",
    "                                    np.array(preds_dict[\"unbound\"][tf][train_species[1]])[alu_labels],\n",
    "                                    tfs_latex_names[plot_index + 2], plot_index, model_names)\n",
    "    \n",
    "    if not save_files:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(\"../plots/scatter_\" + train_species[0] + \"_\" + train_species[1] + \"_alus_\" + str(tf_split_half) + \".png\",\n",
    "                    bbox_inches='tight', pad_inches = 0)\n",
    "        plt.savefig(\"../plots/scatter_\" + train_species[0] + \"_\" + train_species[1] + \"_alus_\" + str(tf_split_half) + \".pdf\",\n",
    "                    bbox_inches='tight', pad_inches = 0)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_bound_unbound_scatters(preds_dict, train_species = [\"mm10\", \"hg38\"], save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_unbound_alu_scatters(preds_dict, train_species = [\"mm10\", \"hg38\"], tf_split_half = 1, skip = SKIP, save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_unbound_alu_scatters(preds_dict, train_species = [\"mm10\", \"hg38\"], tf_split_half = 2, skip = SKIP, save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bound_unbound_scatters(preds_dict, train_species = [\"DA\", \"hg38\"], save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_unbound_alu_scatters(preds_dict, train_species = [\"DA\", \"hg38\"], tf_split_half = 1, save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_unbound_alu_scatters(preds_dict, train_species = [\"DA\", \"hg38\"], tf_split_half = 2, save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bound_unbound_scatters(preds_dict, train_species = [\"NS\", \"hg38\"], save_files = SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_da2)",
   "language": "python",
   "name": "conda_da2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
